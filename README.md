# Reinforce Î¼ Project

This project implements and visualizes reinforcement learning experiments using the REINFORCE algorithm.   
It includes tools for generating learning curves, tracking convergence behaviors, and analyzing the impact of
hyperparameters like learning rate (Î·).

## ğŸ“š Overview

- **Core Implementation**: The REINFORCE algorithm is implemented in the **[reinforce.training](reinforce/training.py)**
  module.
- **Plotting Utilities**: The **[reinforce.plotting](reinforce/plotting.py)** module provides reusable plotting
  functions
  for visualizing learning
  curves and success rates.
- **Constants Management**: The **[exercise.scripts.assignment_constants](exercise/scripts/assignment_constants.py)**
  module defines constants used across experiments, which can be easily modified to adjust simulation parameters.
- **Documentation**: Detailed docstrings and a structured README for easy navigation and understanding, including a
  comprehensive PDF documentation generated using Sphinx (**[reinforce_mu_project.pdf](reinforce_mu_project.pdf)**).
- **Type Annotations**: The codebase uses type annotations for better clarity and maintainability.
- **Modular Design**: The project is structured to allow easy extension and testing of different components.
- **Easy Setup**: Simple setup instructions with a virtual environment and dependency management
  via **[requirements.txt](requirements.txt)**.
- **Results Storage**: Results of the REINFORCE simulations are saved in a specified directory, which can be customized.
- **Testing**: Basic test cases to ensure functionality, with a focus on the REINFORCE algorithm's behavior.

## ğŸ“ Project Structure

```
reinforce_mu_project/
â”œâ”€â”€ reinforce/
â”‚   â”œâ”€â”€ __init__.py                # Package init
â”‚   â”œâ”€â”€ plotting.py                # Plotting utilities for visualizing trajectories and performance
â”‚   â”œâ”€â”€ training.py                # Core REINFORCE training logic
â”‚   â””â”€â”€ utilities.py               # Helper functions (e.g. sampling, reward computation)
â”‚
â”œâ”€â”€ exercise/
â”‚   â”œâ”€â”€ __init__.py                # Marks 'exercise' as a Python package
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ __init__.py            # Package init
â”‚       â”œâ”€â”€ assignment_constants.py # Constant parameters used in experiments
â”‚       â””â”€â”€ main.py                # Entry script for running experiments
â”‚
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md                      # Project documentation (you are here)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ reinforce_mu_project.pdf       # Auto-generated Sphinx PDF documentation
â””â”€â”€ requirements.txt               # Python dependencies
```

## ğŸ›  Setup

### 1. Create Virtual Environment

#### Linux / macOS:

```bash
python3 -m venv .venv
source .venv/bin/activate
```

#### Windows:

```bash
python -m venv .venv
.venv\Scripts\activate
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

## ğŸš€ How to Run

From the project root (**[reinforce_mu_project/](.)**), run:

```bash
python -m exercise.scripts.main
```

This will execute the main REINFORCE simulation pipeline defined in **[main.py](exercise/scripts/main.py)**.

## ğŸ“ˆ Results

The results of the REINFORCE simulations will be saved in the `exercise/plots/` directory.   
This behavior can be customized in the **[assignment_constants.py](exercise/scripts/assignment_constants.py)** file, by
modifying the `save_directories_dict` dictionary.

## ğŸ§ª Features

- Simulates the REINFORCE algorithm across multiple learning rates.
- Computes success rates based on convergence to a target Î¼.
- Plots learning curves and statistics.

## ğŸ“ Constants

The **[assignment_constants.py](exercise/scripts/assignment_constants.py)** file stores default constants such as:

- Target Î¼ value
- Learning rate schedules
- Simulation parameters

## ğŸ“Š Plotting

The **[plotting](reinforce/plotting.py)** module provides reusable plotting utilities for:

- Î¼ trajectory visualization
- Success rate analysis
- Comparison of learning rates

## ğŸ“„ License

MIT License.
See **[LICENSE](LICENSE)** for details.

## ğŸ‘¤ Author

- **Name:** Or Fadida
- **Email:** [orfadida@mail.tau.ac.il](mailto:orfadida@mail.tau.ac.il)
- **GitHub:** [orfadida2000](https://github.com/orfadida2000)
